{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1108e29a3401065cf668315ccca1f10",
     "grade": false,
     "grade_id": "cell-f93bad251821744c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data Visualization with Seaborn and Scikit Learn Decision Trees\n",
    "\n",
    "In this lab, you will learn how to use [Seaborn](https://seaborn.pydata.org/), a popular\n",
    "data visualization package in Python.  Next, it illustrates how to create decision trees\n",
    "in Scikit Learn to perform both classification and regression.  \n",
    "\n",
    "## Activity 1 - Data Visualization\n",
    "Let's start by investigating Scikit learn''s wine dataset.\n",
    "The code block below shows that this data is stored as a *sklearn.utils.Bunch* object.\n",
    "This object is an extension of the Python dictionary class (see the \n",
    "[sklearn.utils.bunch](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html)\n",
    "site for more information).  It enables  you to use it as a dictionary (looking up values by key), or to look up the same variables as attributes.  For example, these two lines of code will both reference the data matrix within a bunch:\n",
    "- wine_data['data']\n",
    "- wine_data.data\n",
    "\n",
    "To start, let's load a few modules and the wine dataset.  The code below will also print \n",
    "out the keys to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "192757abbd0caf517c373fd8e7fa5c32",
     "grade": false,
     "grade_id": "cell-34e9fdd4627847f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wine_data = datasets.load_wine()\n",
    "type (wine_data)\n",
    "\n",
    "for key in wine_data:\n",
    "    print('key:',key,'\\t datatype of value is is:',type(wine_data[key]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38ecc3d6be6b134118d96f4cfa4eee2b",
     "grade": false,
     "grade_id": "studentworkcell1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03myou can write code here to assist in answering \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mthe above questions\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "you can write code here to assist in answering \n",
    "the above questions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "232917d694688f026849baf518620a62",
     "grade": true,
     "grade_id": "act1q",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:red\">Questions</span>\n",
    "\n",
    "1. data and target are numpy arrays. What are the dimensions of these arrays?\n",
    "  \n",
    "## *YOUR ANSWER HERE*\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "2.  *feature_names* is a list. What are the dimensions of the list and do they match any of dimensions of data or target.\n",
    "\n",
    "## *YOUR ANSWER HERE*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "3. What is the difference between target_names and feature_names?\n",
    "\n",
    "## *YOUR ANSWER HERE*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9ac5573d53397e5d66e0102ce39624",
     "grade": false,
     "grade_id": "cell-3e40428fb1f6bd0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "data = wine_data['data']\n",
    "\n",
    "alcoholDist = sns.distplot(data[:,0],kde=False)\n",
    "plt.xlabel(wine_data['feature_names'][0],fontsize=14)\n",
    "plt.ylabel('Count',fontsize=14)\n",
    "\n",
    "plt.savefig(fname='wine_data_alcohol_distribution.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "for i in np.unique(wine_data['target']):\n",
    "    sns.distplot(data[wine_data['target']==i,0],kde=True,label='Class {}'.format(i))\n",
    "plt.legend() \n",
    "plt.xlabel(wine_data['feature_names'][0],fontsize=14)\n",
    "plt.savefig(fname='wine_data_alcohol_distribution_by_class.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Question</span>\n",
    "\n",
    "What does this line shown below of python do in the above code?  How value does it evaluate to and how does it work?\n",
    "\n",
    "\n",
    "**wine_data['target'] == i**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9daba9e10e5fbc5d8f0642235a8283c",
     "grade": true,
     "grade_id": "q4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## *YOUR ANSWER HERE*\n",
    "     \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95f7fe2ac3dbc6534a47688649aa9131",
     "grade": true,
     "grade_id": "act1qs2b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "Create a block of code that draws distribution plots for each of the features in the wine_data \n",
    "bunch.  Your distribution plots need to have the x axis labeled with the feature name\n",
    "(as in the above example).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 3 -- Distributions Visualized with Boxplots\n",
    "\n",
    "A [Boxplot](https://en.wikipedia.org/wiki/Box_plot), or whisker plot, shows\n",
    "the distribution of the data (like the lines do in the above plot), but highlight the quartiles and showcases [outliers](https://en.wikipedia.org/wiki/Outlier), which can skew\n",
    "values like the mean and variance.  \n",
    "\n",
    "Creating boxplots using seaborn is a little tricky using numpy arrays.  Seaborn works well with another python package named [pandas](https://pandas.pydata.org/).  In this course, we will not spend a lot of time working\n",
    "with pandas, but it is a very useful tool.  The second section of the code below copies the sklearn *bunch* \n",
    "into a pandas *dataframe*.  It then draws the boxplot for alcohol again.  Notice that the second chart axis is labeled (a benefit since the pandas dataframe relates the feature_names to the columns of the data).\n",
    "\n",
    "The power of the pandas dataframe is also shown as a set of descritive statistics\n",
    "are printed for the alcohol feature (for the entire dataset and for each class).  Notice\n",
    "that the quartiles shown in the text table line up with the lines and boxes shown\n",
    "in the boxplot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3950c9f8616e31bcfa82b43e8d9d90b3",
     "grade": false,
     "grade_id": "cell-42d983e797aca757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "x = sns.boxplot(x=data[:,0],y=wine_data['target'],orient='h')\n",
    "plt.show()\n",
    "\n",
    "## repeat now using pandas dataframe and Seaborn\n",
    "wine_df = pd.DataFrame(data=wine_data['data'],columns=wine_data['feature_names'])\n",
    "wine_df['target'] = wine_data['target']\n",
    "wine_df['class'] = wine_df['target'].map(lambda ind: wine_data['target_names'][ind])\n",
    "sns.boxplot(x='alcohol',y='class',data=wine_df)\n",
    "plt.rcParams[\"axes.labelsize\"] = 16\n",
    "plt.savefig(fname='wine_data_boxplot_by_class.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n",
    "\n",
    "print(wine_df['alcohol'].describe())\n",
    "print('')\n",
    "\n",
    "print(wine_df.groupby('class')['alcohol'].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ae0ae30953f62eddb960293073277ba",
     "grade": false,
     "grade_id": "act2qs2aq",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:red\">Question</span>\n",
    "\n",
    "- Create code to draw a boxplot for each feature using the data that is in the pandas dataframe (wine_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfd57822e4658aedcdaa78f3cbdf9fc1",
     "grade": true,
     "grade_id": "act2qs2a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Write code to produce a *boxplot* for each feature.\n",
    "## You can use the data in the pandas dataframe and the wine_data bunch.\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64e5066d0b8f47e9ddc2ef60b24d634a",
     "grade": false,
     "grade_id": "cell-adfd4d2b353c6828",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <span style=\"color:red\">Question</span>\n",
    "\n",
    "- What is the approximate value of malic_acid that 25% of the class 2 wine's have a value that is equal to or lower than? (in other words, the 25th percentile)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb0cd80ef19dd37acbc852112cb7024a",
     "grade": true,
     "grade_id": "cell-83cb110d9fe9ccf4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## *YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 4 Building a Decision Tree\n",
    "\n",
    "We will now turn to building a decision tree using sklearn''s **DecisionTreeClassifier**.  To measure node\n",
    "*impurity*, the tree will use **entropy** (as discussed in the prior lab and section 3.3.3 of the IDD textbook).\n",
    "We will start by creating a decision tree with just a single split, which is commonly\n",
    "referred to as a **decision stump**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "classifier = \\\n",
    "    tree.DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "    \n",
    "classifier.fit(wine_data['data'],wine_data['target'])\n",
    "\n",
    "\n",
    "treePlot = tree.plot_tree(classifier)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "treePlot = tree.plot_tree(classifier, feature_names = wine_data['feature_names'])\n",
    "\n",
    "plt.savefig(fname='wine_decisionstump.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7f5aef04a93800f21a35f83073c6b84",
     "grade": false,
     "grade_id": "cell-9b828d048d379ef7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The wine dataset contains 3 classes, but the entropy equation is the same:\n",
    "- $-\\sum_{i=0}^{c - 1} p_i(t)log_{2}p_{i}(t)$ \n",
    "\n",
    "where $p_i(t)$ is the relative frequency of training instances belonging to class $t$ and $c$ is the number of classes (and $0 log_{2}0 = 0$).\n",
    "\n",
    "When classifying a new observation **p** (where the class is not known), the decision tree is traversed until a leaf node is reached.  The class that is it assigns is the **majority** class in the leaf.  \n",
    "\n",
    "# <span style=\"color:red\">Questions</span>\n",
    "- Create a set of python code that:\n",
    "  - What class will be predicted for a wine that has a flavanoid value of 1.4?\n",
    "  - Create examples points to be classified and call the predict member function to classify them\n",
    "    - declares a variable *p1* in the code block below that will be classified by the tree as class 2.\n",
    "    - calls the *predict* member function within the classifier object and assign the return value to a variable named *y1*.  Verify that it is class 2.\n",
    "    - declare a variable *p2* in the same code block that will be classified by the tree as class 0.\n",
    "    - call *predict* sending *p2*, retain the results in a variable named *y2*, and verify that it is class 0 \n",
    "    - create a new numpy matrix, named *test_data*, that holds both *p1* and *p2* and send the matrix to *predict*. You can look at using numpy's [vstack](https://numpy.org/doc/stable/reference/generated/numpy.vstack.html) function to combine p1 and p2 together.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aee5cb84cd1da2912ba56b8e2fea980e",
     "grade": true,
     "grade_id": "cell-9f9b39f53ec9a2f1",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "## *YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fba459eddc07996e4c1ff7f13df4f30",
     "grade": false,
     "grade_id": "act3-dtc-pc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Activity Create datapoints \n",
    "# p1 so that it is classified as class 2\n",
    "# p2 so that is is classifier as class 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "y1_pred = classifier.predict(p1)\n",
    "y2_pred = classifier.predict(p2)\n",
    "y_pred = classifier.predict(test_data)\n",
    "\n",
    "print('y1 class is {}'.format(y1_pred))\n",
    "print('y2 class is {}'.format(y2_pred))\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1c7d85eecab146002d5bc1d31f0e994",
     "grade": true,
     "grade_id": "act3-dtc-pc2-at",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this code verifies that the preceeding block\n",
    "# creates p1 and p2 per the instructions\n",
    "\n",
    "classifier = tree.DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "classifier.fit(wine_data['data'],wine_data['target'])\n",
    "\n",
    "y1_pred = classifier.predict(p1)\n",
    "y2_pred = classifier.predict(p2)\n",
    "y_pred = classifier.predict(test_data)\n",
    "assert(y1_pred[0] == 2)\n",
    "assert(y2_pred[0] == 0)\n",
    "\n",
    "assert(np.array_equal(y_pred,np.array([2, 0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Question</span>\n",
    "Compute the accuracy (in python) by calling the predict member function on \n",
    "*ALL* of the training data (do this in a single call).\n",
    "\n",
    "Use python and numpy (not sklearn) to compute the \n",
    "accuracy of the tree on the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7da74ecd74f7121c4692e1e43cde5426",
     "grade": false,
     "grade_id": "cell-10449c1a27a61123",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Activity 3 Question 2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0557993b5f8d46893107805e7b867641",
     "grade": true,
     "grade_id": "cell-76c62d220c2c3066",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5683934fd86327cd71a44156643f3e8",
     "grade": false,
     "grade_id": "cell-b93520ab56323391",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Activity 5 Regression with Decision Trees\n",
    "\n",
    "While not very common, decision trees can also be used for **regression** (predicting real valued output).\n",
    "Regression is discussed in [Appendix D](https://www-users.cs.umn.edu/~kumar001/dmbook/appendices_2ed.pdf) of the \n",
    "IDD textbook (and is only available online).\n",
    "\n",
    "So far, we have used **accuracy** and **error_rate** as evaluation metrics for classification\n",
    "(end of IDD section 3.2).\n",
    "\n",
    "For regression, we will use the sum of squared error (SSE) and \n",
    "the mean squared error (MSE), which are defined below:\n",
    "- <span style=\"font-family:Papyrus; font-size:1.5em;\">SSE = $\\sum_{i=0}^{n-1} |y_{i} - f(x_{i}) | $ </span>\n",
    "  \n",
    "- <span style=\"font-family:Papyrus; font-size:1.5em;\">MSE = $\\frac{1}{n} SSE$</span>\n",
    "\n",
    "where:\n",
    "- $n$ is the number of data points\n",
    "- $y_{i}$ is the actual value for data point $i$ that we are trying to predict\n",
    "- $x_{i}$ is **ALL** the features (a vector) describing data point $i$ (this\n",
    "excludes the value we are trying to predict).\n",
    "- $f(x_{i})$ is the predicted value from our model $m$, which is represented\n",
    "here as a function named $f$.\n",
    "\n",
    "Decision trees work roughly the same, except that node *impurity* is measured by ***MSE*** instead of entropy.  \n",
    "\n",
    "This section will use the toy data for housing pricing. Let's start by loading a\n",
    "benchmark for regression testing from the 1980sknown as the boston housing dataset. \n",
    "One of the features (zero-based #5) is the number of rooms in the house.  Let's \n",
    "plot that data to see how it correlates to the sales price of the home (the target\n",
    "value of this regression problem).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "boston_data = datasets.load_boston()\n",
    "\n",
    "print(boston_data.DESCR)\n",
    "\n",
    "print(boston_data.data[:,2])    \n",
    "plt.scatter(boston_data.data[:,5],boston_data.target)\n",
    "plt.xlabel('Nbr of Rooms')\n",
    "plt.ylabel('Cost (1k dollars)')\n",
    "plt.savefig(fname='housing_room_vs_cost.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(boston_data.data[:,2],boston_data.data[:,5],boston_data.target)\n",
    "ax.set_xlabel('Nbr of Rooms')\n",
    "ax.set_ylabel('% of industry')\n",
    "ax.set_zlabel('Cost (1k dollars)')\n",
    "#ax.zaxis._axinfo['label']['space_factor'] = 2.8\n",
    "#ax.zaxis.labelpad = 30\n",
    "\n",
    "\n",
    "plt.savefig(fname='housing_rooms_and_industry_vs_cost.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n",
    "\n",
    "## Look at feature 5 and feature "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0f63a4721e6326d36a9b9320d59e96a",
     "grade": false,
     "grade_id": "cell-88ad02046e9c230c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice that there seems to be a relationship between the number\n",
    "of rooms and the price of a home (which makes sense).  \n",
    "\n",
    "Recall that a decision tree classifier labels\n",
    "a new point *p* by traversing the tree until a leaf node is encountered,\n",
    "and then uses the majority class in the leaf node to label point *p* \n",
    "with that class.\n",
    "  \n",
    "[Regression tree's](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html) do not\n",
    "assign class labels but assign a **number (real valued answer)**.  \n",
    "To make a prediction for \n",
    "point *p*, the tree is travsered until a leaf node is reached (the same as before).\n",
    "The predicted value for point *p* is the average value of the predicted variable \n",
    "for the data points in the leaf node.  \n",
    "\n",
    "The predicted target value for regression is commonly\n",
    "referred to as $\\hat{y}$ and the **true** answer is referred to as $y$.  \n",
    "\n",
    "Let's build a regression tree (stump) using the Scikit learn package.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "737f53a9c156148b062cadb75f5a5f64",
     "grade": false,
     "grade_id": "cell-3b1dbc48a181ce37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build a regressor tree using only feature 5 (number of rooms).  The target\n",
    "value of this regression is the median home value (MEDV).\n",
    "\"\"\"\n",
    "regress_classifier = tree.DecisionTreeRegressor(max_leaf_nodes=2)\n",
    "\n",
    "regress_classifier.fit(boston_data['data'],boston_data.target)\n",
    "\n",
    "yhat = regress_classifier.predict(boston_data.data)\n",
    "\n",
    "tree.plot_tree(regress_classifier,feature_names = boston_data.feature_names)\n",
    "plt.savefig(fname='boston_data_regressor_stump.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Question</span>\n",
    "Compute the MSE by calling predict on the tree for all the values\n",
    "in the training set.\n",
    "Assign the MSE to a variable named mse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30385cfa3985a921141ffd7615eb77f9",
     "grade": false,
     "grade_id": "cell-ecf0ff875b1851fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the MSE on the training data\n",
    "and assign to a variable named *mse*.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be0dca23222a245ddf6b26d0ebea1741",
     "grade": true,
     "grade_id": "cell-15a077e8a5df1d6c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "try: mse\n",
    "except NameError:\n",
    "    print('an mse variable is not SET')\n",
    "    assert(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review of Predictions\n",
    "\n",
    "We can vary the number of rooms in the house and see what our model will\n",
    "output, and then plot this over the scatter plot of training points.\n",
    "This visually shows how closely the model is following\n",
    "the training data.  \n",
    "\n",
    "The tree is printed again to allow an easy side by side\n",
    "comparison between the item plots.  Notice that the red line\n",
    "(output from the model) changes direction just as\n",
    "the decision tree split points instruct it to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7af768a6b10127c59f73f17c170bdb2b",
     "grade": false,
     "grade_id": "cell-c9d41ab43dc36558",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the tree\n",
    "\n",
    "tree.plot_tree(regress_classifier,max_depth=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# create a set of input values for rooms\n",
    "# the other variables are not used in the model, but, model\n",
    "# expects values for these other variables\n",
    "\n",
    "\n",
    "X = np.zeros((25,boston_data.data.shape[1]))\n",
    "\n",
    "room_values = np.linspace(4,9,25)\n",
    "X[:,5] = room_values\n",
    "\n",
    "# predict the output\n",
    "yhat =  regress_classifier.predict(X)\n",
    "\n",
    "# plot training data with nbr rooms versus price\n",
    "plt.scatter(boston_data['data'][:,5],boston_data['target'], alpha=0.5)\n",
    "plt.plot(room_values,yhat,c='r',lw=3)\n",
    "plt.xlabel('Nbr of rooms', fontsize=16)\n",
    "plt.ylabel('Price (1k dollars)')\n",
    "plt.savefig(fname='boston_data_stump_room_predictions.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity 6 Larger trees\n",
    "\n",
    "So far we have used a node (decision stump) to simplify our analysis (this\n",
    "also makes some of the visualization much easier). Decision trees can be built having \n",
    "more than one split point.  \n",
    "\n",
    "In this example, the features are being eliminated to just the number of rooms feature\n",
    "to make the analysis easier.  Note that once a feature is selected as a split point, it\n",
    "does **NOT** eliminate it from being selected again for another node.  Thus, an entire\n",
    "tree can be constructed even with a single feature.\n",
    "\n",
    "The code section below builds trees with more than one split point.  Note that the MSE\n",
    "is very low on the training data, meaning our model\n",
    "is doing a great job predicting home prices, right?\n",
    "\n",
    "Note that this tree is a very large tree with 475 leaves.  Recall how many \n",
    "points were in the training data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_classifier = tree.DecisionTreeRegressor()\n",
    "\n",
    "\n",
    "X_single_feature = boston_data.data[:,5].reshape(-1,1)\n",
    "\n",
    "regress_classifier.fit(X_single_feature, boston_data.target)\n",
    "\n",
    "print(\"Training data points: {} Number of leaves: {}\".\n",
    "      format(boston_data.data.shape[0], regress_classifier.get_n_leaves()))\n",
    "\n",
    "\n",
    "yhat = regress_classifier.predict(X_single_feature)\n",
    "\n",
    "mse = np.sum((yhat - boston_data.target)**2)/yhat.size\n",
    "\n",
    "print(\"MSE: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "room_values = np.linspace(4,9,100)\n",
    "\n",
    "yhat =  regress_classifier.predict(room_values.reshape(-1,1))\n",
    "\n",
    "\n",
    "plt.scatter(boston_data['data'][:,5],boston_data['target'], alpha=0.5)\n",
    "\n",
    "plt.plot(room_values,yhat,c='r',lw=3)\n",
    "plt.xlabel('Nbr of rooms', fontsize=16)\n",
    "plt.ylabel('Price (1k dollars)')\n",
    "plt.savefig(fname='boston_data_maxleaves_room_predictions.pdf', dpi=300,bbox_inches='tight',pad_inches=0.05)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('cs445_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "913065499d5b3e602ea105d616d6d7415b791baa6c6e13d4dfd40ad85495d384"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
